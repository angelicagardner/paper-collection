<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <meta content="IE=edge" http-equiv="X-UA-Compatible" />
    <title>Towards a Framework for Monitoring and Analyzing High Performance Computing Environments Using Kubernetes and Prometheus</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="# Towards a Framework for Monitoring and Analyzing High Performance Computing Environments Using Kubernetes and Prometheus" />
    <link href="../../style.css" rel="stylesheet" />
</head>
<body>
    <header>
        <h1><a href="https://angelicagardner.github.io/paper-collection/">Back to Main Table</a></h1>
    </header>
    <main>
        <article>
            <h2>Towards a Framework for Monitoring and Analyzing High Performance Computing Environments Using Kubernetes and Prometheus</h2>
            <p><strong>Year:</strong> 2019</p>
            <p><strong>Labels:</strong>
                
                <span class="label">observability</span>, 
                
                <span class="label">prometheus</span>, 
                
                <span class="label">kubernetes</span>, 
                
                <span class="label">monitoring</span>
                
            </p>
            <div class="content">
                <h1>Towards a Framework for Monitoring and Analyzing High Performance Computing Environments Using Kubernetes and Prometheus</h1>

<p><strong>Author(s):</strong> Nitin Sukhija; Elizabeth Bautista</p>

<p><strong>Paper URL:</strong> https://ieeexplore.ieee.org/document/9060302</p>

<p><strong>Pages:</strong> 6</p>

<p><strong>Summary:</strong> Computing environments for complex calculations and large data processing at high speeds are challenging to manage and monitor, leading to traditional alert methods being inefficient. This paper proposes a framework that integrates with modern platforms where the different components (OMNI, Kubernetes, Prometheus, Grafana) serves different purposes to create unified, dynamic and real-time capacities. This scalable infrastructure will be used for management, monitoring and alerting of heterogeneous computing systems at NERSC.</p>

<h2>Sections Summary</h2>

<h3><code>1. Introduction</code></h3>

<ul>
<li>An HPC (High-Performance Computing) environment is a computing system designed to perform complex calculations and process large amounts of data at high speeds.</li>
<li>Extreme-scale HPC environments require sophisticated automation and orchestration to manage diverse components like compute cores, memory, interconnects, power, and cooling systems.</li>
<li>Monitoring computational centers becomes increasingly challenging as they grow, leading to alert fatigue where true issues are obscured by numerous false alarms.</li>
<li>Traditional alert methods become less effective due to the high volume of alerts.</li>
</ul>

<h3><code>2. Background and Related Work</code></h3>

<ul>
<li>For a monitoring solution to be efficient it needs to take into consideration scalability and HA, automation, dashboards, actionable insight analytics and capacity planning, distribution and customization.</li>
<li>Previous work (project examples) include Trinity Monitoring infrastructure and OpenLorenz.</li>
<li>The proposed monitoring framework in this paper integrates with modern platforms to provide a unified solution and aims to provide dynamic and real-time capacity, and it's specifically designed to handle the monitoring and management needs of extreme-scale systems. </li>
</ul>

<h3><code>3. Design of HPC Monitoring and Analysis Framework</code></h3>

<ul>
<li><em>Figure 1. Overview design of the proposed framework.</em></li>
<li>Data comes from heterogenenous and distributed sources in and out of the data center.</li>
<li>Examples of operational data include:
<ul>
<li>Time series data from the environment (e.g., temperature, power, humidity levels);</li>
<li>Monitoring data (e.g., network speeds, latency, packet loss, utilization or those that monitor the filesystem for disk write speeds, I/O); and</li>
<li>Event data (e.g., system logs, console logs, hardware failure events).</li>
</ul></li>
<li>This diverse data should be kept on a single location and in the same format.</li>
<li>The Operations Monitoring and Notification Infrastructure (OMNI) is a big data collection infrastructure solution created for above purpose and backed by Elasticsearch. Data is getting into Elasticsearch via RabbitMQ (messaging broker). OMNI is able to ingest &gt; 25,000 messages per second.
<ul>
<li>The time series data gathered and aggregated by Prometheus will be stored in OMNI and will be used to display dashboards.</li>
</ul></li>
</ul>

<h3><code>4. Conclusion and Future Work</code></h3>

<ul>
<li>In the proposed framework, each component has specific roles within the architecture, such as Prometheus pulling data, OMNI collecting data, Kubernetes managing the system via deployments of clusters and services, and Grafana real-time visualizing the data.</li>
<li>Future enhancements may include adding various data analysis methods like:
<ul>
<li>Clustering for grouping similar data;</li>
<li>Prescriptive analytics for decision-making; and</li>
<li>Statistical analysis to detect significant system changes and alert.</li>
</ul></li>
<li>Different alert mechanisms could also be integrated to notify administrators of system problems in alternative ways.</li>
</ul>

            </div>
        </article>
    </main>
</body>
</html>